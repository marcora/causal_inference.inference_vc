# Introduction to causal inference and do-calculus

<https://www.inference.vc/untitled>

First of all, causal inference differentiates between two types of conditional distributions one might want to derive from a joint distribution $p(x, y, z, \ldots)$:

$$
p(y \mid x)
$$

$$
p(y \mid \text{do}(x))
$$

The first is the distribution of $y$ given that I observe $X = x$, i.e., the *observational* conditional distribution.

The second is the distribution of $y$ given that I assign the value $x$ to $X$ ($X := x$), i.e., the *interventional* conditional distribution.

$p(y \mid x)$ and $p(y \mid \text{do}(x))$ are not generally the same, and you can verify this with a simple thought experiment.

Let's say we jointly observe $X$ (ice cream sales) and $Y$ (shark attacks). They are correlated/statistically dependent and therefore seeing $X = x$ allows me to predict the value of $Y$, but $Y$ is not caused by $X$ and therefore setting the value of $X$ to $x$ won't affect the distribution of $Y$. In other words:

$$
p(y \mid x) \ne p(y)
$$

$$
p(y \mid \text{do}(x)) = p(y)
$$

Depending on the purpose of your statistical model, you should seek to estimate one of these conditionals. If your ultimate goal is diagnosis or forecasting (i.e. observing a naturally occurring $x$ and inferring the probable values of \$y\$) you want the observational conditional $p(y \mid x)$. This is what we already do in supervised learning and regression analysis. But if $x$ is a medical treatment and $y$ is the disease outcome, you are not merely interested in diagnosis or forecasting. You are interested in inferring the effect of administering $x$ on $y$.

$p(y \mid \text{do}(x))$ is in fact a vanilla conditional distribution, but it's not computed based on the joint distribution $p(x, y, z, \ldots)$, but rather based on a modified joint distribution $p'(x, y, z, \ldots)$ where the mechanism that generates $X$ has been replaced by a mechanism that always outputs $x$. This is the joint distribution which we would observe if we actually carried out the intervention in question. $p(y \mid \text{do}(x))$ is the conditional distribution we would learn from data collected in an experiment like a randomized controlled trial or A/B test where the experimenter controls x. Note that actually carrying out the intervention or experiment may be impossible or at least impractical or unethical in many situations.

The main point of causal inference and do-calculus is: If I cannot estimate $p(y \mid \text{do}(x))$ directly with a randomized controlled trial, can I estimate it based on data I observed outside of a controlled experiment?

XXX

Coming up with a causal model is a modeling step where we have to consider assumptions about how the world works, what causes what. Once we have a causal diagram, we can emulate the effect of intervention by mutilating the causal graph: deleting all edges that lead into the node in the $\text{do}$ operator.

The mapping from causal diagrams to joint distributions is many-to-one: several causal diagrams are compatible with the same joint distribution. Thus, it is generally impossible to conclusively choose between different causal explanations by looking at observed data only.

Do-calculus extends probability theory with four additional rules we can apply to conditional distributions with the $\text{do}$ operator in them. These rules take into account properties of the causal diagram. Here is [an introductory paper on them](https://arxiv.org/abs/1305.5506?ref=inference.vc).

Ideally, as a result of a do-calculus derivation you end up with an equivalent formula for $p(y \mid \text{do}(x))$ which no longer has any $\text{do}$ operators in them, so you estimate it from observational data alone. If this is the case we say that the causal query $p(y \mid \text{do}(x))$ is *identifiable*. Conversely, if this is not possible, no matter how hard we try applying do-calculus, we call the causal query *non-identifiable*, which means that we won't be able to estimate it from the data we have.

You can never fully verify the validity and completeness of your causal diagram based on observed data alone. However, there are certain aspects of the causal model which are empirically testable. In particular, the causal diagram implies certain conditional independence or dependence relationships between sets of variables. These dependencies or independencies can be empirically tested, and if they are not present in the data, that is an indication that your causal model is wrong. Taking this idea forward you can attempt to perform full causal discovery: attempting to infer the causal model or at least aspects of it, from empirical data.

But the bottom line is: a full causal model is a form of prior knowledge that you have to add to your analysis in order to get answers to causal questions without actually carrying out interventions. Reasoning with data alone won't be able to give you this. Unlike priors in Bayesian analysis - which are a nice-to-have and can improve data-efficiency - causal diagrams in causal inference are a must-have. With a few exceptions, all you can do without them is running randomized controlled experiments.
